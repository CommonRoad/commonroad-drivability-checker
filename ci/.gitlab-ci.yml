stages:
  - static-check
  - compile
  - build-wheels
  - test
  - docs
  - deploy

.update-git-config: &update-git-config
  - git config --global url."https://gitlab-ci-token:${CI_JOB_TOKEN}@gitlab.lrz.de/".insteadOf "git@gitlab.lrz.de:"
  - git config --global url."https://gitlab-ci-token:${CI_JOB_TOKEN}@gitlab.lrz.de".insteadOf "ssh://git@gitlab.lrz.de"

# default CI image
default:
  image: $CI_REGISTRY/tum-cps/commonroad-docker/ci-base:2025.2
  before_script:
    - *update-git-config

.python-versions: &python-versions
  - &default-python-version "3.10"
  - "3.11"
  - "3.12"
  - "3.13"


### static test ###
clang-tidy:
  stage: static-check
  script:
    - mkdir build && cd build
    - cmake -DCMAKE_BUILD_TYPE=Debug -DCMAKE_EXPORT_COMPILE_COMMANDS=ON ..
    - cd ..
    - bash ./ci/clang-tidy.sh
  needs: [ ]

### compile C++ library ###
# cache dependencies for quicker build (here only commonroad-cmake)
.cache-build-dir:
  cache: &cache_dependency_archives
    key: cache-dependency-archives
    paths:
      - build/_deps/*-subbuild/*-populate-prefix/src/*.{tar*,zip}
    policy: pull

generate-cache:
  stage: compile
  cache:
    <<: *cache_dependency_archives
    policy: push
  script:
    - cmake -G "Ninja Multi-Config" -S . -B build -DFETCHCONTENT_QUIET:BOOL=OFF
  needs: [ ]

# build GCC
build-gcc:
  stage: compile
  cache:
    <<: *cache_dependency_archives
  image: $CI_REGISTRY/tum-cps/commonroad-docker/ci-gcc:2025.2
  parallel:
    matrix:
      - GCC_VERSION: [ 10, 11, 12, 13, 14 ]
  variables:
    CC: x86_64-linux-gnu-gcc-$GCC_VERSION
    CXX: x86_64-linux-gnu-g++-$GCC_VERSION
  script:
    - cmake -G "Ninja Multi-Config" -S . -B build
    - cmake --build build --config Release
  needs: [ ]

# build Clang
build-clang:
  stage: compile
  cache:
    <<: *cache_dependency_archives
  image: $CI_REGISTRY/tum-cps/commonroad-docker/ci-clang:2025.2
  parallel:
    matrix:
      - CLANG_VERSION: [ 15, 16, 17, 18, 19 ]
  variables:
    CC: clang-$CLANG_VERSION
    CXX: clang++-$CLANG_VERSION
  script:
    - apt-get remove -y libomp-dev &&
      apt-get update &&
      apt-get install -y --no-install-recommends libomp-$CLANG_VERSION-dev
    - cmake -G "Ninja Multi-Config" -S . -B build
    - cmake --build build --config Release
  needs: [ ]


### build wheels ###
# build wheel rules
.common-rules:
  rules:
    # Rule to disable a job for merge request pipelines (imitate default job behaviour)
    - &skip_merge_request_pipeline
      if: $CI_PIPELINE_SOURCE == "merge_request_event"
      when: never
    - &skip_scheduled_pipeline
      if: $CI_PIPELINE_SOURCE == "schedule"
      when: never
    - if: &full_wheel_build_condition $CI_COMMIT_TAG || $CI_COMMIT_REF_PROTECTED == "true" || $CI_COMMIT_REF_NAME == $CI_DEFAULT_BRANCH || $CI_COMMIT_REF_NAME =~ /^(master|development)$/

# build source distribution
build-sdist:
  stage: build-wheels
  image: $CI_REGISTRY/tum-cps/commonroad-docker/wheelenv:2025.2
  script:
    - python3 --version
    - python3 -m build --sdist
  needs: [ ]
  artifacts:
    paths:
      - dist/*.tar.gz
    expire_in: 30 minutes

build-wheel:
  stage: build-wheels
  image: quay.io/pypa/manylinux2014_x86_64:latest
  variables:
    # pretend to CMake that we are using cibuildwheel to build the wheel
    CIBUILDWHEEL: "1"
  parallel:
    matrix:
      - PYTHON_VERSION: *python-versions
  script:
    - python$PYTHON_VERSION -m pip wheel -v -w built_wheel dist/*.tar.gz
    - auditwheel repair -w wheelhouse built_wheel/commonroad_drivability_checker-*.whl
  needs:
    - job: build-sdist
      artifacts: true
  artifacts:
    paths:
      - wheelhouse/*.whl
    expire_in: 30 minutes


## build wheel distribution with cibuildwheel
build-wheel-cibw:
  stage: build-wheels
  # Use the privileged runner as required for Docker-in-Docker (dind)
  tags:
    - dind
  image: $CI_REGISTRY/tum-cps/commonroad-docker/wheelenv:2025.2
  # make a docker daemon available for cibuildwheel to use
  services:
    - name: docker:20.10-dind
      entrypoint: [ "env", "-u", "DOCKER_HOST" ]
      command: [ "dockerd-entrypoint.sh" ]
  variables:
    DOCKER_HOST: tcp://docker:2375/
    DOCKER_DRIVER: overlay2
    DOCKER_TLS_CERTDIR: ""
    CIBW_BEFORE_ALL: "git config --global url.\"https://gitlab-ci-token:${CI_JOB_TOKEN}@gitlab.lrz.de//\".insteadOf \"git@gitlab.lrz.de:\" && git config --global url.\"https://gitlab-ci-token:${CI_JOB_TOKEN}@gitlab.lrz.de/\".insteadOf \"ssh://git@gitlab.lrz.de\""
    # NOTE: The following variables correspond to the default values.
    # They are specified here so that it is possible to override them using
    # Gitlab push options or in the UI when running a manual pipeline.
    #
    # For example, use git push -o ci.variable="CIBW_BUILD_VERBOSITY=1"
    # to make cibuildwheel verbose in the pipeline created for the pushed commit.
    CIBW_BUILD_VERBOSITY: 1
    # We skip pytest for this stage, since we have a separate stage for running pytest
    CIBW_TEST_SKIP: "*"
    # We only use the artifacts (sdist/wheels) from previous jobs, so skip all Git operations
    GIT_STRATEGY: none
  script:
    - pipx run 'cibuildwheel == 2.*' dist/*.tar.gz
  needs:
    - job: build-sdist
      artifacts: true
  artifacts:
    paths:
      - wheelhouse/*.whl
    expire_in: 30 minutes
  rules:
    # We only run the docker-in-docker job on protected branches
    - if: $CI_COMMIT_REF_PROTECTED == "false"
      when: never
    - *skip_merge_request_pipeline
    # When we are building wheels for a tag/release, build wheel for all supported Python versions and platform
    # Also routinely build all wheels for the default branch as well as develop (commits on these branches are infrequent)
    - if: *full_wheel_build_condition
      variables:
        CIBW_BUILD: "*"
    # Fallback rule when we're not building wheels for a tag or a main branch:
    # In that case, build only manylinux wheels to speed up the pipeline
    - when: on_success
      variables:
        CIBW_BUILD: "*-manylinux_x86_64"

### run unit tests ###
.test-setup:
  &test-setup
  stage: test
  image: python:${PYTHON_VERSION}-slim-bullseye
  before_script:
    # we need build-essential, since Polygon3 has to be compiled from source
    - apt-get update && apt-get install -y --no-install-recommends git build-essential
    # use pip-tools to generate a requirements_test.txt (including test dependencies)
    # we want to install the packages from the previously built wheel and not pull the PyPi packages
    - pip install pip-tools
    - pip-compile --extra=test -o requirements_test.txt pyproject.toml
    - pip install -r requirements_test.txt
    - pip install --no-index --find-links=wheelhouse/ commonroad-drivability-checker[test]
  parallel:
    matrix:
      - PYTHON_VERSION: *python-versions

.source-manual:
  &source-manual
  needs:
    - job: build-wheel
      artifacts: true
  rules:
    - *skip_merge_request_pipeline
    - if: $CI_COMMIT_REF_PROTECTED == "false"

.source-cibw:
  &source-cibw
  needs:
    - job: build-wheel-cibw
      artifacts: true
  rules:
    - *skip_merge_request_pipeline
    - if: $CI_COMMIT_REF_PROTECTED == "true"

.pytest-setup:
  &pytest-setup
  <<: *test-setup
  script:
    - cd tests
    - python run_tests.py

run-pytest:
  <<: [ *pytest-setup, *source-manual ]

run-pytest-cibw:
  <<: [ *pytest-setup, *source-cibw ]


### documentation ###
# build the documentation (Doxygen + Sphinx)
build-sphinx:
  stage: docs
  image: python:${PYTHON_VERSION}-slim-bullseye
  variables:
    PYTHON_VERSION: *default-python-version
  before_script:
    # we need build-essential, since Polygon3 has to be compiled from source
    - apt-get update && apt-get install -y --no-install-recommends git build-essential doxygen pandoc
    # use pip-tools to generate a requirements_docs.txt (including doc dependencies)
    # we want to install the packages from the previously built wheel and not pull the PyPi packages
    - pip install pip-tools
    - pip-compile --extra=docs -o requirements_docs.txt pyproject.toml
    - pip install -r requirements_docs.txt
    - pip install --no-index --find-links=wheelhouse/ commonroad-drivability-checker[docs]
  script:
    - cmake -S . -B build -DCR_DC_BUILD_DOCS=ON
    - cmake --build build --target Sphinx
  needs:
    - job: build-wheel
      artifacts: true
      parallel:
        matrix:
          - PYTHON_VERSION: *default-python-version
  artifacts:
    paths:
      - build/doc/sphinx
    expire_in: 30 minutes

### deploy wheels to PyPi ###
# upload to internal PyPi registry
push-to-internal-registry:
  stage: deploy
  image: $CI_REGISTRY/tum-cps/commonroad-docker/wheelenv:2025.2
  variables:
    TWINE_USERNAME: gitlab-ci-token
    TWINE_PASSWORD: ${CI_JOB_TOKEN}
    TWINE_REPOSITORY_URL: ${CI_API_V4_URL}/projects/${CI_PROJECT_ID}/packages/pypi
    UPLOAD_WHEELS: "0"
    # We only use the artifacts (sdist/wheels) from previous jobs, so skip all Git operations
    GIT_STRATEGY: none
  script:
    - twine upload dist/*.tar.gz wheelhouse/*.whl
  needs:
    - job: build-sdist
      artifacts: true
    - job: build-wheel
      artifacts: true
      optional: true
    - job: build-wheel-cibw
      artifacts: true
      optional: true
  rules:
    # Disable job for merge request pipelines (imitate default job behaviour)
    - *skip_merge_request_pipeline
    - *skip_scheduled_pipeline
    - if: $CI_COMMIT_BRANCH == "development"
      when: manual
    # Also upload wheels if the UPLOAD_WHEELS was manually set to true
    # For example, use git push -o ci.variable="UPLOAD_WHEELS=1" to test this
    - if: $UPLOAD_WHEELS == "1"


# push built wheels to the external PyPi test registry
# at: https://test.pypi.org/project/commonroad-drivability-checker/
push-to-external-pypi-test-registry:
  stage: deploy
  image: $CI_REGISTRY/tum-cps/commonroad-docker/wheelenv:2025.2
  variables:
    TWINE_USERNAME: __token__
    TWINE_PASSWORD: ${CR_PYPI_TEST_API_TOKEN}
    TWINE_REPOSITORY: testpypi
    GIT_STRATEGY: none
  script:
    - twine upload dist/*.tar.gz wheelhouse/*.whl
  needs:
    - job: build-sdist
      artifacts: true
    - job: build-wheel-cibw
      artifacts: true
  rules:
    # Disable job for merge request pipelines (imitate default job behaviour)
    - *skip_merge_request_pipeline
    - *skip_scheduled_pipeline
    - if: $CI_COMMIT_BRANCH == "master"
      when: manual


# push built wheels to the external PyPi registry
push-to-external-pypi-registry:
  stage: deploy
  image: $CI_REGISTRY/tum-cps/commonroad-docker/wheelenv:2025.2
  variables:
    TWINE_USERNAME: __token__
    TWINE_PASSWORD: ${CR_PYPI_RELEASE_API_TOKEN}
    GIT_STRATEGY: none
  script:
    - twine upload dist/*.tar.gz wheelhouse/*.whl
  needs:
    - job: build-sdist
      artifacts: true
    - job: build-wheel-cibw
      artifacts: true
  rules:
    # Disable job for merge request pipelines (imitate default job behaviour)
    - *skip_merge_request_pipeline
    - *skip_scheduled_pipeline
    - if: $CI_COMMIT_BRANCH == "master"
      when: manual


### publish documentation ###
pages:
  # Push the latest documentation of the development branch to the GitLab Pages
  # at https://cps.pages.gitlab.lrz.de/commonroad-drivability-checker/
  stage: deploy
  script:
    - mv ./build/doc/sphinx public
  needs:
    - job: build-sphinx
      artifacts: true
  artifacts:
    paths:
      - public
  environment:
    name: Gitlab Pages
    url: https://cps.pages.gitlab.lrz.de/commonroad-drivability-checker/
  rules:
    # Disable job for merge request pipelines (imitate default job behaviour)
    - *skip_merge_request_pipeline
    - *skip_scheduled_pipeline
    - if: $CI_COMMIT_BRANCH == "master"
      when: manual
